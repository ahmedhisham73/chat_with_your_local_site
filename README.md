# ğŸ” Secure Local Chatbot System (Frontend + Backend + Monitoring)

A complete secure local AI-based chatbot system with:

- Frontend built using **React** (no Tailwind)
- Backend services (Auth + MCP for summarization + LLM)
- Full Dockerized deployment with NGINX + TLS + Monitoring

---

## ğŸ“ Features

- âœ… JWT-based Login Authentication
- âœ… Protected Routing (`/page_1`)
- âœ… Responsive Layout (Sidebar + Content + EgyptBot Chatbot)
- âœ… Chatbot supports both **OpenAI** and **LLaMA.cpp**
- âœ… HTTPS with TLS (NGINX reverse proxy)
- âœ… Prometheus + Grafana Monitoring
- âœ… Structured JSON logging (Nginx)
- âœ… No Tailwind or Bootstrap â€” clean manual CSS

---

## ğŸ—ï¸ Tech Stack

- React + Vite
- Flask (Auth + MCP)
- OpenAI API + llama.cpp integration
- NGINX (TLS, HTTP2, Reverse Proxy, Rate Limiting)
- Prometheus + Grafana (Monitoring)
- Docker Compose (isolated services, single network)

---

## ğŸ”‘ Pages

| Route       | Description                              |
|-------------|------------------------------------------|
| `/login`    | JWT-based login page                     |
| `/page_1`   | Protected page with static Egypt history + EgyptBot |
| `/tools`    | Dynamic tool metadata tester (RAG-friendly)

---

## ğŸ§  Chatbot Integration

- Located inside `Page1.jsx`
- Supports **model switching** between:
  - `openai`
  - `llamacpp`
- Dynamic prompt sent to unified backend `/invoke/llm`
- Sample JSON payload:
  ```json
  {
    "input": {
      "prompt": "Ù…Ù† Ù‡Ùˆ Ø±Ù…Ø³ÙŠØ³ Ø§Ù„Ø«Ø§Ù†ÙŠØŸ",
      "model": "llamacpp"
    }
  }
  ```

---

## âš™ï¸ Backend Endpoints

### ğŸ”¹ `/invoke/llm` (POST)
Unified LLM endpoint

| Field     | Type   | Description          |
|-----------|--------|----------------------|
| prompt    | string | User input           |
| model     | string | "openai" or "llamacpp" |

Returns:
```json
{
  "backend": "llamacpp",
  "response": "..."
}
```

---

### ğŸ”¹ `/tool-metadata.json` (GET)
Returns JSON metadata used in `/tools` page for dynamic tool rendering.

### ğŸ”¹ `/metrics` (GET)
Exposes Prometheus metrics for `auth_service` and `mcp_service`.

---

## ğŸ§© Directory Structure

```
LLM_MCP/
â”œâ”€â”€ auth_service/           # Login / JWT
â”œâ”€â”€ mcp_service/            # Summarization & LLM API
â”œâ”€â”€ LLM_service/            # llama.cpp backend, models, logic
â”œâ”€â”€ frontend/               # React app with EgyptBot
â”œâ”€â”€ monitoring/             # Prometheus + Grafana provisioning
â”œâ”€â”€ docker-compose-merged.yml
```

---

## ğŸ” Docker & Network

- All services share the `shared_net` (bridge network)
- NGINX acts as HTTPS reverse proxy
- Mounted frontend `dist/` inside NGINX as root
- Rate limiting, gzip compression, and security headers enabled

---

## âš ï¸ Notes

- `.env` **is no longer required** in frontend (`REACT_APP_MCP_HOST` was removed)
- API routing now uses `https://localhost/invoke/llm`
- NGINX TLS cert path: `./auth_service/certs/`
- No Tailwind; pure CSS via `Page1.css`

---

## ğŸš€ Run Locally

```bash
# Build frontend:
cd frontend
npm install
npm run build

# Go back and run all services:
cd ..
docker compose -f docker-compose-merged.yml up --build
```

---

## ğŸ” Access

| Component     | URL                    |
|---------------|------------------------|
| Frontend      | https://localhost      |
| Grafana       | http://localhost:3000  |
| Prometheus    | http://localhost:9090  |
| Backend (API) | proxied via NGINX      |

---

## âœ… Default Login (for testing)

| Username | Password   |
|----------|------------|
| `admin`  | `admin123` |

---

## ğŸ“œ License

MIT License
